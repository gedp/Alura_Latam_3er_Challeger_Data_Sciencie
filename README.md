# ğŸ¤– Challenge Telecom X - Parte 2: PredicciÃ³n de CancelaciÃ³n (Churn)

## ğŸ¯ DescripciÃ³n del Proyecto
Bienvenido al Challenge Telecom X - Parte 2, un proyecto avanzado de ciencia de datos del programa ONE de Alura LATAM. En esta etapa, me desempeÃ±o como cientÃ­fico de datos en Telecom X desarrollando un sistema predictivo para identificar clientes con alto riesgo de cancelaciÃ³n de servicios (churn).

El objetivo principal es implementar un flujo completo de Machine Learning para predecir la probabilidad de abandono de clientes, permitiendo a la empresa tomar acciones preventivas y estratÃ©gicas para reducir la tasa de abandono y optimizar la retenciÃ³n de clientes.

## ğŸ¯ Objetivos del DesafÃ­o
* ğŸ§¹ **Preparar los datos** para el modelado (tratamiento, codificaciÃ³n, normalizaciÃ³n).
* ğŸ” **Realizar anÃ¡lisis de correlaciÃ³n** y selecciÃ³n de variables para identificar los factores mÃ¡s influyentes.
* ğŸ¤– **Entrenar dos o mÃ¡s modelos** de clasificaciÃ³n (Random Forest, XGBoost, CatBoost, KNN).
* ğŸ“Š **Evaluar el rendimiento** de los modelos con mÃ©tricas exhaustivas (Accuracy, Precision, Recall, F1-Score, ROC-AUC).
* ğŸ” **Interpretar los resultados**, incluyendo la importancia de las variables.
* ğŸ“ **Crear una conclusiÃ³n estratÃ©gica** seÃ±alando los principales factores que influyen en la cancelaciÃ³n.

## ğŸ’» TecnologÃ­as Utilizadas
* **Python 3.8+**
* **Pandas:** ManipulaciÃ³n y anÃ¡lisis de datos.
* **NumPy:** CÃ¡lculos numÃ©ricos.
* **Matplotlib:** VisualizaciÃ³n de datos.
* **Seaborn:** Visualizaciones estadÃ­sticas.
* **Scikit-learn:** Preprocesamiento, modelado y evaluaciÃ³n.
* **XGBoost:** Algoritmo de gradient boosting optimizado.
* **CatBoost:** Algoritmo de gradient boosting para variables categÃ³ricas.
* **Plotly:** Visualizaciones interactivas.
* **Pickle:** SerializaciÃ³n de modelos.
* **Google Colab:** Entorno de desarrollo.

## ğŸ“ Estructura del Proyecto
<img width="782" height="450" alt="image" src="https://github.com/user-attachments/assets/46231f4d-7844-48ac-8764-10c6f984c963" />



## ğŸ”„ Proceso de Machine Learning Implementado
### 1. AnÃ¡lisis Exploratorio de Datos (EDA)
* âœ… **Carga y exploraciÃ³n inicial:** AnÃ¡lisis de estructura y composiciÃ³n de datos.
* âœ… **AnÃ¡lisis de variables numÃ©ricas:** Distribuciones, correlaciones y outliers.
* âœ… **AnÃ¡lisis de variables categÃ³ricas:** Tasas de abandono por segmentos.
* âœ… **Visualizaciones comprehensivas:** GrÃ¡ficos de barras, boxplots, histogramas y mapas de calor.

### 2. Preprocesamiento de Datos
* âœ… **Limpieza de datos:** EliminaciÃ³n de columnas irrelevantes (ID Cliente, Costo Diario).
* âœ… **CodificaciÃ³n de variables:** One-Hot Encoding para variables categÃ³ricas.
* âœ… **NormalizaciÃ³n:** StandardScaler para variables numÃ©ricas.
* âœ… **DivisiÃ³n de datos:** Train/Test split (80/20) con estratificaciÃ³n.

### 3. Entrenamiento de Modelos
* âœ… **Random Forest:** 100 Ã¡rboles, `max_depth=10`, optimizado para evitar overfitting.
* âœ… **XGBoost:** 100 estimadores, `learning_rate=0.1`, con regularizaciÃ³n integrada.
* âœ… **CatBoost:** 100 iteraciones, optimizado para variables categÃ³ricas.
* âœ… **KNN:** 5 vecinos, con distancia euclidiana.

### 4. EvaluaciÃ³n y OptimizaciÃ³n
* âœ… **MÃ©tricas exhaustivas:** Accuracy, Precision, Recall, F1-Score, ROC-AUC.
* âœ… **ValidaciÃ³n cruzada:** 5-fold cross-validation para robustez.
* âœ… **OptimizaciÃ³n de hiperparÃ¡metros:** GridSearchCV para Random Forest y XGBoost.
* âœ… **AnÃ¡lisis de overfitting:** ComparaciÃ³n de rendimiento `train` vs `test`.

### 5. InterpretaciÃ³n y Deploy
* âœ… **Importancia de variables:** AnÃ¡lisis de `feature importance`.
* âœ… **SelecciÃ³n de modelo:** ElecciÃ³n basada en F1-Score y ROC-AUC.
* âœ… **SerializaciÃ³n:** Guardado del modelo optimizado para producciÃ³n.
* âœ… **FunciÃ³n de predicciÃ³n:** ImplementaciÃ³n para nuevos datos.

## ğŸ“Š Resultados del Modelado
### MÃ©tricas de Rendimiento por Modelo
| Modelo | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
|---|---|---|---|---|---|
| ğŸŒ³ Random Forest | 0.842 | 0.812 | 0.789 | 0.800 | 0.891 |
| ğŸš€ XGBoost | 0.851 | 0.828 | 0.801 | 0.814 | 0.902 |
| ğŸ± CatBoost | 0.847 | 0.821 | 0.795 | 0.808 | 0.895 |
| ğŸ¯ KNN | 0.798 | 0.745 | 0.721 | 0.733 | 0.842 |
| ğŸ† XGBoost Optimizado | 0.863 | 0.841 | 0.823 | 0.832 | 0.921 |

### Hallazgos Principales
#### 1. DistribuciÃ³n de Churn
* Tasa de Churn identificada: **27.0%** ğŸ“‰
* Clientes totales analizados: **7,043** ğŸ‘¥
* Clientes que abandonaron: **1,902** ğŸ˜”
* Clientes que permanecen: **5,141** ğŸ˜Š

#### 2. Variables MÃ¡s Importantes (Top 10)
| Variable | Importancia XGBoost | Importancia Random Forest | Impacto |
|---|---|---|---|
| â±ï¸ DuraciÃ³n del Contrato (meses) | 18.34% | 16.82% | ğŸ”´ CrÃ­tico |
| ğŸ“‹ Tipo de Contrato_Mes a mes | 16.82% | 14.57% | ğŸ”´ CrÃ­tico |
| ğŸ’° Costo Total | 13.42% | 12.89% | ğŸ”´ CrÃ­tico |
| ğŸŒ Servicio de Internet_Fibra Ã“ptica | 7.43% | 8.21% | ğŸŸ¡ Alto |
| ğŸ”’ Seguridad en LÃ­nea | 6.55% | 5.98% | ğŸŸ¡ Alto |
| ğŸ›¡ï¸ ProtecciÃ³n del Dispositivo | 5.19% | 4.87% | ğŸŸ¡ Medio |
| ğŸ‘¨â€ğŸ’¼ Soporte TÃ©cnico | 4.57% | 4.23% | ğŸŸ¡ Medio |
| ğŸ’³ Costo Mensual | 4.22% | 4.56% | ğŸŸ¡ Medio |
| ğŸ“± MÃ©todo de Pago_Cheque electrÃ³nico | 3.90% | 3.74% | ğŸŸ¡ Medio |
| ğŸ“‹ Tipo de Contrato_Dos aÃ±os | 3.77% | 3.45% | ğŸŸ¢ Bajo |

#### 3. Correlaciones Significativas con Churn
| Variable | CorrelaciÃ³n | RelaciÃ³n |
|---|---|---|
| â±ï¸ DuraciÃ³n del Contrato | -0.35 | Inversa ğŸ“‰ |
| ğŸ’° Costo Mensual | +0.19 | Directa ğŸ“ˆ |
| ğŸŒ Servicio de Internet_Fibra Ã“ptica | +0.31 | Directa ğŸ“ˆ |
| ğŸ”’ Seguridad en LÃ­nea | -0.17 | Inversa ğŸ“‰ |

### Visualizaciones Generadas
* ğŸ“Š **DistribuciÃ³n de Churn:** GrÃ¡fico circular mostrando la proporciÃ³n de abandono.
* ğŸ“ˆ **Matriz de CorrelaciÃ³n:** Mapa de calor con relaciones entre variables.
* ğŸ¯ **Importancia de Variables:** GrÃ¡ficos de barras con `feature importance`.
* ğŸ“Š **ComparaciÃ³n de Modelos:** GrÃ¡ficos de barras con mÃ©tricas de rendimiento.
* ğŸ“‰ **Curvas ROC:** ComparaciÃ³n de rendimiento de clasificadores.
* ğŸ“‹ **Matrices de ConfusiÃ³n:** AnÃ¡lisis detallado de errores de clasificaciÃ³n.

## ğŸ¯ Conclusiones y Recomendaciones
### Conclusiones Clave
* **Modelo seleccionado:** XGBoost optimizado con F1-Score de 0.832 y ROC-AUC de 0.921.
* **Factores de mayor riesgo:**
    * Los clientes con contratos `Mes a Mes` tienen 2.5x mÃ¡s probabilidad de abandonar.
    * La `DuraciÃ³n del Contrato` es el factor mÃ¡s influyente (correlaciÃ³n inversa de -0.35).
    * El servicio de `Fibra Ã“ptica` muestra mayor tasa de abandono (41.9% vs 28.1% DSL).
* **Patrones identificados:**
    * Los clientes nuevos (<12 meses) son los mÃ¡s vulnerables al abandono.
    * La falta de servicios de seguridad y soporte aumenta el riesgo significativamente.
    * El mÃ©todo de pago con `Cheque ElectrÃ³nico` estÃ¡ fuertemente asociado al churn.
* **Recomendaciones EstratÃ©gicas:**
    * ğŸ¯ **Programa de RetenciÃ³n Proactiva:**
        * Implementar un sistema de alertas tempranas usando el modelo predictivo.
        * Asignar ejecutivos de cuenta a clientes con probabilidad de churn > 0.6.
        * Ofrecer descuentos personalizados basados en el perfil de riesgo.
    * ğŸ“‹ **Estrategia de Contratos:**
        * Ofrecer 20% de descuento por contratos anuales a clientes `Mes a Mes`.
        * Implementar programa de lealtad con beneficios progresivos por antigÃ¼edad.
        * Crear planes de transiciÃ³n suave de mensual a anual.
    * ğŸŒ **Mejora de Servicios:**
        * Investigar problemas de calidad en servicio de `Fibra Ã“ptica`.
        * Incluir seguridad y soporte tÃ©cnico en planes base.
        * Desarrollar paquetes integrados con mÃºltiples servicios.
    * ğŸ’³ **OptimizaciÃ³n de Pagos:**
        * Ofrecer 5% de descuento por mÃ©todos de pago automÃ¡ticos.
        * Simplificar proceso de cambio de `Cheque ElectrÃ³nico` a otros mÃ©todos.
        * Implementar recordatorios inteligentes de pago.
    * ğŸ“Š **Monitoreo Continuo:**
        * Establecer `dashboard` en tiempo real de mÃ©tricas de churn.
        * Realizar reentrenamiento trimestral del modelo predictivo.
        * Implementar anÃ¡lisis A/B para evaluar la efectividad de las estrategias.

### MÃ©tricas de Ã‰xito Propuestas
* **ReducciÃ³n de Churn:** Meta del 25% en 6 meses.
* **RetenciÃ³n Clientes Nuevos:** Aumentar a 85% en primeros 3 meses.
* **Contratos Largo Plazo:** Incrementar en 30% la adopciÃ³n.
* **SatisfacciÃ³n Cliente:** Mejorar NPS en 15 puntos.

## ğŸš€ CÃ³mo Ejecutar el Proyecto
### Prerrequisitos
* Python 3.8 o superior.
* Cuenta de Google Colab (opcional).
* LibrerÃ­as especificadas en `requirements.txt`.

### EjecuciÃ³n en Google Colab (Recomendado)
1.  ğŸ“‚ Abrir Google Colab: `colab.research.google.com`.
2.  ğŸ“‹ Crear nuevo notebook: `File` â†’ `New notebook`.
3.  ğŸ“‹ Copiar el cÃ³digo: Copiar todo el cÃ³digo del archivo `TelecomX_Churn_Prediction.ipynb`.
4.  ğŸ“‹ Pegar y ejecutar: Pegar en las celdas del notebook y ejecutar.
5.  ğŸ“Š Ver resultados: El anÃ¡lisis se ejecutarÃ¡ automÃ¡ticamente mostrando todas las visualizaciones.

### EjecuciÃ³n Local
# clonar el repositorio
git clone [https://github.com/tu-usuario/challenge3-data-science-alura-latam.git](https://github.com/tu-usuario/challenge3-data-science-alura-latam.git)
cd challenge3-data-science-alura-latam

# instalar dependencias
pip install -r requirements.txt

# ejecutar el notebook
jupyter notebook TelecomX_Churn_Prediction.ipynb
Uso del Modelo Entrenado
Python

# Cargar modelo y preprocesador
import pickle

with open('modelo_xgboost_reducido.pkl', 'rb') as f:
    modelo = pickle.load(f)

with open('preprocessor.pkl', 'rb') as f:
    preprocessor = pickle.load(f)

# Preprocesar nuevos datos y predecir
datos_procesados = preprocessor.transform(nuevos_datos)
predicciones = modelo.predict(datos_procesados)
probabilidades = modelo.predict_proba(datos_procesados)[:, 1]
ğŸ“ Archivos Generados
Archivo	Formato	DescripciÃ³n
modelo_xgboost_reducido.pkl	PKL	Modelo optimizado para producciÃ³n
preprocessor.pkl	PKL	Preprocesador de datos
feature_names.pkl	PKL	Nombres de caracterÃ­sticas
matriz_correlacion.png	PNG	Mapa de calor de correlaciones
distribucion_churn.png	PNG	GrÃ¡fico de distribuciÃ³n de abandono
importancia_variables.png	PNG	AnÃ¡lisis de feature importance
comparacion_modelos.png	PNG	ComparaciÃ³n de mÃ©tricas entre modelos
curvas_roc.png	PNG	Curvas ROC de los modelos
resultados_prediccion.csv	CSV	Predicciones para nuevos datos
Exportar a Hojas de cÃ¡lculo

ğŸ† Logros del Proyecto
âœ… Pipeline de ML completo: ImplementaciÃ³n exitosa de EDA, preprocesamiento, modelado y evaluaciÃ³n.

âœ… MÃºltiples algoritmos comparados: EvaluaciÃ³n exhaustiva de 4 modelos de clasificaciÃ³n.

âœ… OptimizaciÃ³n avanzada: GridSearchCV para encontrar mejores hiperparÃ¡metros.

âœ… MÃ©tricas de alto rendimiento: F1-Score de 0.832 y ROC-AUC de 0.921 con XGBoost.

âœ… InterpretaciÃ³n completa: AnÃ¡lisis de importancia de variables y factores de riesgo.

âœ… Modelo production-ready: SerializaciÃ³n y funciÃ³n de predicciÃ³n para uso en producciÃ³n.

âœ… Recomendaciones accionables: Estrategias concretas basadas en insights del modelo.

âœ… CÃ³digo replicable: SoluciÃ³n escalable, documentada y fÃ¡cil de implementar.

---

### ğŸ“ Nota: Este proyecto fue desarrollado como parte del Challenge 3 de Alura LATAM para demostrar competencias avanzadas en ciencia de datos, machine learning y anÃ¡lisis predictivo.

â­ Si este proyecto te fue Ãºtil, Â¡considera darle una estrella! â­

---
Hecho con â¤ï¸ por: [SynergyaTech](https://synergya.tech)
